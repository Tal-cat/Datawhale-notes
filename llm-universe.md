# llm-universe     
2024.06     
教程地址：https://github.com/datawhalechina/llm-universe/tree/main      
     
第一章 大模型简介    
第一节 大语言模型LLM理论简介     
1. 目前模型：（1）国外：GPT-3.5、GPT-4、PaLM、Claude和 LLaMA 等；（2）国内：文心一言、讯飞星火、通义千问、ChatGLM、百川等。
2. GPT小知识：（1）decoder-only；（2）ChatGPT 最长支持32,000字符，知识截止2021年9月；（3）GPT-4经历了RLHF，对恶意或挑衅性查询的响应相对更为安全。    
3. LLaMA小知识：（1）对每个Transformer子层的输入进行了RMSNorm归一化/正则化；（2）：将ReLU替换为SwiGLU激活函数；（3）模型的输入不再使用位置编码，而是在网络的每一层添加了位置编码；（4）LLaMA3的上下文长度增加了一倍，使用分组查询注意力（GQA，Grouped-Query Attention），将查询（query）分组并在组内共享键（key）和值（value）。
4. LLM的能力总结：
（1）涌现能力，即量变引起质变。包含1）上下文学习：GPT-3 首次引入，允许模型通过理解上下文并生成相应输出的方式来执行任务，而【无需额外的训练或参数更新】；2）指令遵循；3）逐步推理：采用思维链（CoT, Chain of Thought）推理策略，利用包含中间推理步骤的提示机制来解决这些任务。（2）作为基座模型支持多元应用的能力：多个应用可以只依赖于一个或少数几个大模型进行统一建设。（3）支持对话作为统一入口的能力：如Auto-GPT、微软 Jarvis 等。
5. LLM的特点：（1）巨大的规模：（2）预训练和微调：首先在大规模文本数据上进行预训练（【无标签】数据），学习通用的语言表示和知识。然后通过微调（【有标签】数据）适应特定任务；（3）上下文感知；（4）多语言支持：【个人认为这个由训练决定，可能不算特点？】；（5）多模态支持；（6）伦理和风险问题；（7）高计算资源需。

第二节 检索增强生成（RAG, Retrieval-Augmented Generation）简介    
1. LLM目前问题：信息偏差/幻觉、知识更新滞后性、内容不可追溯（LLM生成的内容往往缺乏明确的信息来源，影响内容的可信度。RAG将生成内容与检索到的原始资料建立链接，增强了内容的可追溯性）、领域专业知识能力欠缺、推理能力限制、应用场景适应性受限及长文本处理能力较弱（LLM在理解和生成长篇内容时受限于有限的上下文窗口，且【必须按顺序处理内容】，输入越长，速度越慢）。
2. RAG 的工作流程：分为数据处理、检索、增强和生成四个阶段。
3. RAG和微调（fine tune, 通过在特定数据集上进一步训练大语言模型，来提升模型在特定任务上的表现），见截图。
   ![image](https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/36551e64-d46f-44d4-bc3f-fed4d7dca83a)

第三节 LangChain简介    
1. 目标是为各种大型语言模型应用提供通用接口，从而简化应用程序的开发流程。具体来说，LangChain 框架可以实现数据感知和环境互动，也就是说，它能够让语言模型与其他数据来源连接，并且允许语言模型与其所处的环境进行互动。见下图：
   ![image](https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/bc373449-1424-4625-b932-38c3b9c24343)
2. 核心组件：（1）模型输入/输出（Model I/O）：与语言模型交互的接口；（2）数据连接（Data connection）：与特定应用程序的数据进行交互的接口；（3）链（Chains）：将组件组合实现端到端应用。比如后续我们会将搭建检索问答链来完成检索问答。（4）记忆（Memory）：用于链的多次运行之间持久化应用程序状态；（5）代理（Agents）：扩展模型的推理能力。用于复杂的应用的调用序列；（6）回调（Callbacks）：扩展模型的推理能力。用于复杂的应用的调用序列。
3. 目前稳定版本v0.1.0，保持向后兼容性。
4. LangChain生态包括：（1）LangChain Community；（2）LangChain Core，就是核心库、核心组件；（3）LangChain CLI 命令行工具；（4）LangServe部署服务；LangSmith开发者平台。

第四节 开发LLM应用的整体流程     
1. 大模型开发更多是一个【工程】问题。在大模型开发中，一般不会去大幅度改动模型，而是将大模型作为一个【调用工具】，通过【Prompt Engineering、数据工程、业务逻辑分解等】手段来充分发挥大模型能力，适配应用任务。
2. 大模型开发：用【Prompt Engineering】来替代子模型的训练调优，通过 Prompt 链路组合来实现业务逻辑，用【一个通用大模型 + 若干业务Prompt】来解决任务，将传统的模型训练调优转变成了【Prompt 设计调优】。
3. 评估思路上，从实际业务需求出发【构造小批量验证集】，设计合理Prompt来满足验证集效果。然后，将不断从业务逻辑中收集当下 Prompt的【BadCase】，并将Bad Case加入到验证集中，【针对性优化Prompt】，最后实现较好的泛化效果。下图为对比图：
   ![image](https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/84531ceb-0dc8-40e1-9c04-4414ba80a27d)
4. 大模型开发的一般流程：（1）确定目标；（2）设计功能：越清晰、深入的业务逻辑理解往往也能带来更好的Prompt效果。首先要确定应用的核心功能，然后延展设计核心功能的上下游功能；（3）搭建整体架构：目前，绝大部分大模型应用都是采用的【特定数据库+Prompt+通用大模型】的架构。推荐【基于LangChain框架】进行开发。LangChain 提供了 Chain、Tool 等架构的实现；（4）搭建数据库：个性化大模型应用需要有个性化数据库进行支撑；（5）Prompt Engineering；（6）验证迭代：在大模型开发中是极其重要的一步，【一般指通过不断发现Bad Case并针对性改进Prompt Engineering来提升系统效果、应对边界情况】。（7）前后端搭建：采用 Gradio 和 Streamlit。

第五~七节为实战，略。     

第二章 使用LLM API开发应用     
第一节 基本概念     
1. 每一次访问大模型的【输入】为一个【Prompt】，而【大模型的返回结果】为【Completion】。
2. Tempereture: 一般取值在【0~1】，当取值较低接近【0】时，预测的随机性会较低，产生【更
保守、可预测】的文本，不太可能生成意想不到或不寻常的词。当取值较高接近【1】时，预测的随机性会较高，所有词被选择的可能性更大，会产生更【有创意、多样化】的文本，更有可能生成不寻常或意想不到的词。
3. System prompt: 与User prompt相对，【整个会话过程中持久】地影响模型的回复，且相比于普通 Prompt 具有【更高的重要性】。比如GPT里面可以定制：【你是一个摸鱼高手】的system prompt，这时候用户输入【努力干活】，结果可能还是【摸鱼】。

第二节 使用LLM API 【比较实操，但目前看是用在jupyter noteook cell里写prompt，不如直接用网页写？操作部分略过，代码参见教程github链接】    

第三节 Prompt Engineering提示词工程【近期很火HOT🔥🔥🔥】     
1. 重要性：决定了其能力上限与下限。
2. 设计的【2个原则】：（1）编写清晰、具体的指令。“Adding more context helps the model understand you better.”；（2）给予模型充足思考时间。
3. 原则一：编写清晰、具体的指令：
（1）使用分隔符清晰地表示输入的不同部分【便于读取】：防止【提示词注入（Prompt Rejection），感觉翻译为提示词失效/拒绝/否认等可能更好？】→就是用户输入的文本可能与预设Prompt冲突的内容，如果不加分隔，这些输入就可能“注入”并操纵语言模型，轻则导致模型产生毫无关联的不正确的输出，严重的话可能造成应用的安全风险；
（2）寻求结构化的输出【计算机的长处】：按照某种格式组织的内容，例如JSON、HTML等；
（3）要求模型检查是否满足条件【相当于if-else语句】：如果任务包含不一定能满足的假设（条件），可以告诉模型【先检查这些假设】，如果不满足，则会指出并停止执行后续的完整流程。还可以考虑可能出现的边缘情况及模型的应对；
(4)提供少量示例【人工给模板，监督学习】:"Few-shot" prompting（少样本提示），即在要求模型执行实际任务之前，给模型提供一两个参考样例，让模型了解我们的要求和期望的输出样式。
4. 原则二：给模型时间去思考：通过Prompt引导语言模型进行深入思考。可以要求其先列出对问题的各种看法，说明推理依据，然后再得出最终结论。在Prompt中【添加逐步推理的要求】，能让语言模型【投入更多时间逻辑思维】，输出结果也将更可靠准确。
（1）指定完成任务所需的步骤。
（2）指导模型在下结论之前找出一个自己的解法。注意：若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉” (Hallucination)。

第三章 搭建知识库【学到这里感觉有些像h2o项目，之前就是这个把docker跑崩了==#】     
第一节 词向量及向量知识库     
1. Embedding嵌入：一种将非结构化数据，如单词、句子或者整个文档，转化为实数向量的技术。下图：
   <img width="526" alt="截屏2024-06-24 20 20 48" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/517a0bbe-ca9b-485a-b040-8b7fa923f6d6">
2. Embedding背后思想是相似或相关的对象在嵌入空间中的距离应该很近。下图：
   <img width="496" alt="截屏2024-06-24 20 22 08" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/af4a0ae5-3b5d-42cd-bfbf-358108df0c02">
3. Word Embedding词向量优势：（1）词向量比文字更适合检索：词向量中包含了原文本的语义信息，可以通过计算问题与数据库中数据的点积、余弦距离、欧几里得距离等指标，直接获取问题与数据在语义层面上的相似度；（2）词向量比其它媒介的综合信息能力更强：可以通过多种向量模型将多种数据映射成统一的向量形式。
4. 构建词向量方法：(1)使用各个公司的 Embedding API；(2)在本地使用嵌入模型将数据构建为词向量。
5. 向量数据库优势：数据以向量作为基本单位，对向量进行【存储、处理及检索】。向量数据库通过计算【与目标向量的余弦距离、点积等】获取与目标向量的相似度。当处理大量甚至海量的向量数据时，向量数据库【索引】和【查询算法】的【效率明显高于传统数据库】。
6. 主流向量数据库：（1）Chroma；（2）Weaviate；（3）Qdrant。

第二节 使用Embedding API【代码实践部分，参见原文链接即可】      
     
第三节 数据处理    
1. 本地数据库：通过前文Embedding方法将【本地文档的内容】转化为【词向量】来构建向量数据库。
2. 清洗举例：洗掉\n等。
3. 文档分割：原因：单个文档的长度往往会【超过模型支持的上下文】，导致检索得到的知识【太长超出模型的处理能力】。处理：对文档进行分割，将单个文档按长度或者按固定的规则分割成若干个chunk，然后将每个chunk转化为词向量，存储到向量数据库中。
4. 检索时会以【chunk】作为【检索的元单位】，也就是每一次检索到k个chunk作为模型可以参考来回答用户问题的知识，k为自由设定。
5. chunk_size指每个块包含的【字符或Token（如单词、句子等）】的数量。chunk_overlap指两个块之间【共享的字符数量】，用于保持上下文的连贯性，避免分割丢失上下文信息。见下图：
   <img width="568" alt="截屏2024-06-24 20 32 21" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/6c01ebb8-1e3e-48d6-9af0-d0e84afd2667">

第四节 搭建并使用向量数据库【实践为主，大部分略】   
1. Chroma的相似度搜索使用的是余弦距离。
2. MMR检索：最大边际相关性 (MMR, Maximum marginal relevance)可以帮助我们在保持相关性的同时，增加内容的丰富度。核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。

第四章 构建RAG应用【实践部署多】    
第一节 LLM接入LangChain     
1. LangChain内置了 OpenAI、LLAMA等大模型的调用接口。但没有内置所有大模型，允许用户【自定义】LLM类型。
2. 在开发大模型应用时，大多数情况下【不会】直接将【用户的输入直接传递给LLM】。通常会将用户输入【添加到一个较大的文本】中，称为【PromptTemplates提示模板】，该文本提供有关当前特定任务的附加上下文。
3. 聊天模型的接口是基于消息（message），而不是原始的文本。

第二节 构建检索问答链    
1. 同过前面的本地数据库，加上我们的本地知识，可以帮助LLM做出更好的回答。也有助于缓解大模型的“幻觉”问题。

第三节 部署知识助手【Streamlit实现】      
我的一个Streamlit部署的网页计算器参见： https://tal-cat-28-day-all-cause-mortality-prediction-hf-predict-7rbxqk.streamlit.app/     

第五章 系统评估与优化【有些内容前后都说了好几遍，感觉可以整合】       
第一节 如何评估LLM应用     
<img width="499" alt="截屏2024-06-28 20 31 32" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/07bfc773-cdf7-4b88-88b8-6aa3bc35a679">      
1. 难点：在没有简单答案甚至没有标准答案的情况下实现评估。
2. 思路：将不断涌现的Bad Case(s)逐步加入到验证集，从而形成一个有一定规模的验证集。
3. 基于RAG范式开发的大模型应用包括两个核心部分：【检索】和【生成】，评估则聚焦【优化系统检索精度】和【确定在给定材料下的生成质量】。
4. 每一次优化之后，我们会重新对验证集中【所有验证案例】进行验证，从而保证优化后的系统【不会在原有Good Case(s)上失去能力或表现降级】。
5. 人工评估的一般思路【针对指标建议直接说二分类/连续变量，目前表述不太清晰】：
   （1）量化评估：有一定的评估规范，以保证不同评估员之间评估的相对一致。
   （2）多维评估：从多个维度出发，设计每个维度的评估指标，在每个维度上都进行打分，从而综合评估系统性能。应当【和量化评估有效结合】，对每一个维度，可以设置相同的量纲也可以设置不同的量纲。本项目中可用：
   ① 知识查找正确性：评估系统查找到的知识片段是否能够对问题做出回答。该维度为二分类0或1评估。打分为0指查找到的知识片段不能做出回答，打分为1指查找到的知识片段可以做出回答。
   ② 回答一致性：评估系统的回答是否针对用户问题展开，是否有偏题、错误理解题意的情况，该维度为连续变量【0到1】，0为完全偏题，1为完全切题，中间结果可以任取。
   ③ 回答幻觉比例：综合系统回答与查找到的知识片段，评估系统的回答是否出现幻觉，幻觉比例有多高。该维度为连续变量【0到1】,0为全部是模型幻觉，1为没有任何幻觉。
   ④ 回答正确性：评估系统回答是否正确，是否充分解答了用户问题，是系统最核心的评估指标之一。该维度为连续变量【0到1】。     
   【上述四个维度都围绕知识、回答的正确性展开，与问题高度相关；接下来几个维度将围绕大模型生成结果的拟人性、语法正确性展开，与问题相关性较小：
   ⑤ 逻辑性：评估系统回答是否逻辑连贯，是否出现前后冲突、逻辑混乱的情况。为二分类0或1评估。
   ⑥ 通顺性：评估系统回答是否通顺、合乎语法，连续变量【0到1】。
   ⑦ 智能性：评估系统回答是否拟人化、智能化，是否能充分让用户混淆人工回答与智能回答。连续变量【0到1】。
   综合评分时还可以计算所有维度的平均得分来评估系统的得分，也可以针对不同维度的不同重要性赋予权值，再计算所有维度的加权平均来代表系统得分。
6. 大模型评估复杂的原因：生成模型的答案很难判别，即客观题评估判别很简单，主观题评估判别则很困难。处理方法：在【牺牲一定评估准确性】的情况下，可以将复杂的没有标准答案的主观题进行转化，从而变成有标准答案的问题。两种方法：【构造客观题】与【计算标准答案相似度（使用BLEU）】。
7. 【构造客观题】与【计算标准答案相似度（使用BLEU）】两种方法问题：
   ① 需要人工构造标准答案。对于一些垂直领域可能是一件困难的事情；
   ② 通过相似度来评估可能存在问题。例如，如果生成回答与标准答案【高度一致但在核心的几个地方恰恰相反】导致答案完全错误，bleu得分仍然会很高；
   ③ 计算与标准答案一致性方法的【灵活性很差】，如果模型生成了比标准答案更好的回答，但评估得分反而会降低；
   ④ 无法评估回答的智能性、流畅性。如果回答是各个标准答案中的【关键词拼接】出来的，人们认为这样的回答是不可用无法理解的，但bleu得分会较高。
8. 使用大模型进行评估：
   ① 目标是迭代改进Prompt以提升大模型表现，所选用的评估大模型需要有【优于所使用的大模型】基座的性能。    
   ② 大模型同样存在能力的边界。如果问题与回答太复杂、知识片段太长或是要求评估维度太多，即使是 GPT-4 也会出现错误评估、错误格式、无法理解指令等情况，针对这些情况，我们建议考虑如下方案来提升大模型表现：
   1）改进 Prompt Engineering：尤其注意是否遵守了基本准则、核心建议等；
   2）拆分评估维度。如果【评估维度太多】，模型可能会出现错误格式导致返回无法解析，可以考虑将待评估的多个维度拆分，每个维度调用一次大模型进行评估，最后得到统一结果；
   3）合并评估维度。如果【评估维度太细】，模型可能无法正确理解以至于评估不正确，可以考虑将待评估的多个维度合并，例如，将逻辑性、通顺性、智能性合并为智能性等；
   4）提供详细的评估规范；
   5）提供少量示例。
9. 混合评估：
   ①客观正确性：指对于一些有固定正确答案的问题，模型可以给出正确的回答。可以使用【构造客观题】的方式来进行模型评估。
   ②主观正确性：指对于没有固定正确答案的主观问题，模型可以给出正确的、全面的回答。可以使用【大模型评估】的方式来评估模型回答是否正确。
   ③智能性：指模型的回答是否足够拟人化。可以少量抽样进行人工评估其智能性。
   ④知识查找正确性：指对于特定问题，从知识库检索到的知识片段是否正确、是否足够回答问题。推荐使用【大模型评估】。同时，该维度评估结果【结合主观正确性可以计算幻觉情况】，即如果主观回答正确但知识查找不正确，则说明产生了模型幻觉。

第二节 评估并优化生成部分      
1. RAG全称为检索增强生成，有两个核心部分：检索部分和生成部分。【检索部分的核心功能】是保证系统根据用户query能够查找到对应的答案片段。【生成部分的核心功能】是保证系统在获得了正确的答案片段之后，可以充分发挥大模型能力生成一个满足用户要求的正确回答。
2. 生成部分在已限定使用的大模型基座的情况下，往往会通过优化Prompt Engineering来优化生成的回答：
   ①提升直观回答质量。
   ②标明知识来源，提高可信度：要求模型在生成回答时注明知识来源，这样可以避免模型杜撰并不存在于给定资料的知识，同时，也可以提高对模型生成答案的可信度。
   ③构造思维链：模型本身存在一些能力的限制，例如大模型的幻觉、无法理解较为复杂的指令、无法执行复杂步骤等。可以通过构造思维链，将Prompt构造成一系列步骤来尽量减少其能力限制。
   ④增加一个指令解析。

第三节 评估并优化检索部分     
1. 对于系统能【成功检索】到的query，才能进一步【优化Prompt】来提高系统性能。对于系统【检索失败】的query，必须【改进检索系统】来优化检索效果。但以上要保证我们的每一个验证query的【正确答案都确实存在于知识库中】。
2. 优化检索的思路：
   ①知识片段被割裂导致答案丢失：检索到的知识片段将正确答案分割开了，导致不能形成一个完整、合理的答案。该种问题在【需要较长回答的query】上较为常见。优化思路：【优化文本切割方式】，传统根据特定字符和chunk大小进行分割，但该类分割方式往往不能照顾到文本语义，容易造成同一主题的强相关上下文被切分到两个chunk中。
   ②query提问需要长上下文概括回答：是需要跨越多个 chunk 来综合回答问题。优化思路：【优化知识库构建方式】。可以增加一个步骤，通过使用LLM来对长文档进行概括总结，或者预设提问让LLM做出回答，从而将此类问题的可能答案预先填入知识库作为单独的chunk。
   ③关键词误导：这种情况一般源于query中有多个关键词，其中【次要关键词的匹配】效果影响了主要关键词。优化思路：【对用户query进行改写】。改写成一种合理的形式，去除次要关键词以及可能出现的错字、漏字的影响。
   ④匹配关系不合理：匹配到的强相关文本段并没有包含答案文本。问题在于【使用的向量模型和一开始的假设不符】。即【假设匹配到的强相关文本段就是问题对应的答案文本】。【举例】但是很多向量模型其实构建的是“配对”的语义相似度而 非“因果”的语义相似度，例如对于 query-“今天天气怎么样”，会认为“我想知道今天天气”的相关性比“天气不错”更高。优化思路：【优化向量模型或是构建倒排索引】。    

第六章 LLM应用精选案例【主要是example和code，记录部分相对少，有一些对项目的期待】      
第一节 案例一：个人知识库助手    
1. 架构
   <img width="650" alt="截屏2024-06-30 18 52 03" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/d590ccb8-6c7c-4d3c-b574-3373002bbeba">
2. 期望：部署后允许用户自行上传文档，构建个性化知识库，做到有所应用【很是期待~】。

第二节 案例二：人情世故大模型      
1. 人情世故小助手Tianji（天机），SocialAI（来事儿AI）制作-架构：
   <img width="704" alt="截屏2024-06-30 18 54 17" src="https://github.com/Tal-cat/Datawhale-LLM-universe-notes/assets/60603537/ac4c7ac6-17aa-4475-9481-d29a2677038c">
2. 期望：可以更进一步，增加记忆功能之类的，将使用者的人际关系输入，通过大模型建立人际网络，进而更准确的应对任务并生成问答。

【结语】Datawhale 6月的组队学习就要告一段落啦~ 愉快的旅程~ AI夏令营以及7月再见哦~     

【完结撒花~~~】


   






    









